{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://raw.githubusercontent.com/sokjc/WinnersCircle/master/assets/WinnersCircle-small-icononly.png\" width=200 />\n",
    "\n",
    "## Winner's Circle: RL Workshop\n",
    "\n",
    "# Part 03: Deep Q-Learning\n",
    "Inspired by the Deep Mind Paper [\"Playing Atari with Deep Reinforcement Learning\"](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf), this section will introduce a popular strategy for RL and layer a complication with the Double Deep Q-Learning (DDQN). Most of the code and instructional material is directly adapted from Greg Surma's medium series on Solving Games with AI. \n",
    "\n",
    "The goal of this session will be to introduce you to an algorithm that can successfuly play any game by pixels alone. \n",
    "\n",
    "DQN is a RL technique that is aimed at choosing the best action for given circumstances (observation). Each possible action for each possible observation has its Q value, where 'Q' stands for a quality of a given move. But how do we end up with accurate Q values? Enter deep neural networks.\n",
    "\n",
    "For each state experienced by the agent, the algorithm remebers it. The algo then replays the experience by sampling experiences from memory and updating is Q value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "Since all Atari games have pixels, we can use them to generalize a model across games instead of creating a model speficic to each game world. \n",
    "\n",
    "### Observations\n",
    "\n",
    "Consider one frame:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*uQn5fCSJ4u4F0dXyhu2bpw.png\" width=200px />\n",
    "\n",
    "**Group Discussion**\n",
    "\n",
    "* Is one frame enough for our to predict what to do? \n",
    "* Or do we need more information?\n",
    "\n",
    "Now consider four frames: \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*r_zU8YRUSSr56E0Wr9ZQcQ.png\" width=800px />\n",
    "\n",
    "**Group Discussion**\n",
    "\n",
    "* Why might four frames be better?\n",
    "* What are the draw backs of using four frames as single observation?\n",
    "\n",
    "### Resizing the Observations\n",
    "Four frames of 210x160 RGB arrays that Attari outputs is a lot of information for our model to handle. Let's do two preprocessing steps: change the images to greyscale and scale downscale the size of over all image. Our final array will be 84x84x4 - much easier to handle.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*ChDEq-Leap9J5T5h6nYBzg.png\" width=800px />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "We will be using the architecture from the Deep Mind Paper: \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*3ZgGbUpEyAZb9POWijRq4Q.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jsokoll/Documents/WinnersCircle\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/jsokoll/Documents/WinnersCircle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from game_models.ddqn import DDQNTrainer, DDQNSolver\n",
    "from game_models.ge import GETrainer, GESolver\n",
    "from gym_wrappers import MainGymWrapper\n",
    "\n",
    "# Plotting\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES_IN_OBSERVATION = 4\n",
    "FRAME_SIZE = 84\n",
    "INPUT_SHAPE = (FRAMES_IN_OBSERVATION, FRAME_SIZE, FRAME_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Atari: \n",
    "    \n",
    "    def __init__(self, game_name, game_mode, render=False, total_step_limit=5000, total_run_limit=None, clip=True):\n",
    "\n",
    "        env_name = game_name + \"Deterministic-v4\" #Handles frame skippings (4) at every iteration\n",
    "        env = MainGymWrapper.wrap(gym.make(env_name))\n",
    "        self._main_loop(self._game_model(game_mode, game_name, env.action_space.n), env, render, total_step_limit, total_run_limit, clip)\n",
    "        \n",
    "    def _main_loop(self, game_model, env, render, total_step_limit, total_run_limit, clip):\n",
    "        if isinstance(game_model, GETrainer):\n",
    "            game_model.genetic_evolution(env)\n",
    "\n",
    "        run = 0\n",
    "        total_step = 0\n",
    "        while True:\n",
    "            if total_run_limit is not None and run >= total_run_limit:\n",
    "                print(\"Reached total run limit of: \" + str(total_run_limit))\n",
    "                exit(0)\n",
    "\n",
    "            run += 1\n",
    "            current_state = env.reset()\n",
    "            \n",
    "            if render:\n",
    "                img = plt.imshow(env.render(mode='rgb_array'))\n",
    "                \n",
    "            step = 0\n",
    "            score = 0\n",
    "            while True:\n",
    "                if total_step >= total_step_limit:\n",
    "                    print(\"Reached total step limit of: \" + str(total_step_limit))\n",
    "                    exit(0)\n",
    "                total_step += 1\n",
    "                step += 1\n",
    "\n",
    "                if render:\n",
    "                    img.set_data(env.render(mode='rgb_array')) # just update the data\n",
    "                    display.display(plt.gcf())\n",
    "                    display.clear_output(wait=True)\n",
    "\n",
    "                action = game_model.move(current_state)\n",
    "                next_state, reward, terminal, info = env.step(action)\n",
    "                if clip:\n",
    "                    np.sign(reward)\n",
    "                score += reward\n",
    "                game_model.remember(current_state, action, reward, next_state, terminal)\n",
    "                current_state = next_state\n",
    "\n",
    "                game_model.step_update(total_step)\n",
    "\n",
    "                if terminal:\n",
    "                    game_model.save_run(score, step, run)\n",
    "                    break\n",
    "        \n",
    "    def _game_model(self, game_mode,game_name, action_space):\n",
    "        if game_mode == \"ddqn_training\":\n",
    "            return DDQNTrainer(game_name, INPUT_SHAPE, action_space)\n",
    "        elif game_mode == \"ddqn_testing\":\n",
    "            return DDQNSolver(game_name, INPUT_SHAPE, action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached total step limit of: 200\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Atari('SpaceInvaders', 'ddqn_training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* Surma, Greg. [*__Cartpole - Introduction to Reinforcement Learning (DQN - Deep Q-Learning): Solving OpenAI Gym Environment__*](https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288). 26 September, 2018."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MarioRL",
   "language": "python",
   "name": "mariorl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
